<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh, en"><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="zh, en" /><updated>2022-02-26T20:55:45-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jiawei Lu</title><subtitle>Hello World!  I&apos;m Jiawei Lu, a Master Student at Columbia University.  My research interest is Computer Vision, Deep Learning and Reinforcement Learning.
</subtitle><author><name>Jiawei Lu</name><email>jl5999@columbia.edu</email></author><entry><title type="html">NLP Lecture 02</title><link href="http://localhost:4000/studylog/NLP_lecture02.html" rel="alternate" type="text/html" title="NLP Lecture 02" /><published>2022-02-26T00:00:00-05:00</published><updated>2022-02-26T00:00:00-05:00</updated><id>http://localhost:4000/studylog/NLP_lecture02</id><content type="html" xml:base="http://localhost:4000/studylog/NLP_lecture02.html">&lt;p&gt;Keywords: Language Classification, Probability Review, Machine Learning Background, Naive Bayes’ Classifier.&lt;/p&gt;

&lt;h2 id=&quot;linguistic-terminology&quot;&gt;Linguistic Terminology&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sentence: Unit of written language.&lt;/li&gt;
  &lt;li&gt;Utterance: Unit of spoken language.&lt;/li&gt;
  &lt;li&gt;Word Form: the inflected form as it actually appears in the corpus. “produced”&lt;/li&gt;
  &lt;li&gt;Word Stem: The part of the word that never changes between morphological variations. “produc”&lt;/li&gt;
  &lt;li&gt;Lemma: an abstract base form, shared by word forms, having the same stem, part of speech, and word sense – stands for the class of words with stem. “produce”&lt;/li&gt;
  &lt;li&gt;Type: number of distinct words in a corpus (vocabulary size).&lt;/li&gt;
  &lt;li&gt;Token: Total number of word occurrences.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tokenization&quot;&gt;Tokenization&lt;/h2&gt;
&lt;p&gt;The process of segmenting text (a sequence of characters) into a sequence of tokens (words).&lt;/p&gt;

&lt;h2 id=&quot;lemmatization&quot;&gt;Lemmatization&lt;/h2&gt;
&lt;p&gt;Converting Lemmas into their base form.&lt;/p&gt;

&lt;h2 id=&quot;probabilities-in-nlp&quot;&gt;Probabilities in NLP&lt;/h2&gt;
&lt;p&gt;Probabilities make it possible to combine evidence from multiple sources systematically to (using Bayesian statistics).&lt;/p&gt;

&lt;h3 id=&quot;bayesian-statistics&quot;&gt;Bayesian Statistics&lt;/h3&gt;

&lt;p&gt;Typically, we observe some evidence (for example, words in a document) and the goal is to infer the “correct” interpretation (for example, the topic of a text). Probabilities express the degree of belief we have in the possible interpretations.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Prior probabilities: Probability of an interpretation prior to seeing any evidence.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conditional (Posterior) probability: Probability of an interpretation after taking evidence into account.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;probability-basics&quot;&gt;Probability Basics&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;sample space \(\Omega\)&lt;/li&gt;
  &lt;li&gt;random variable \(X\)&lt;/li&gt;
  &lt;li&gt;probability distribution \(P(\omega)\)&lt;/li&gt;
  &lt;li&gt;joint probability: \(P(A, B)\)&lt;/li&gt;
  &lt;li&gt;conditional probability: 
\(P(A|B) = \frac{P(A,B)}{P(B)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bayes-rule&quot;&gt;Bayes’ Rule&lt;/h3&gt;
&lt;p&gt;\begin{equation}
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\end{equation}&lt;/p&gt;

&lt;h3 id=&quot;independence&quot;&gt;Independence&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Independent:
    &lt;ul&gt;
      &lt;li&gt;
\[P(A) = P(A|B)\]
      &lt;/li&gt;
      &lt;li&gt;
\[P(A, B) = P(A) \cdot P(B)\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conditionally Independent
    &lt;ul&gt;
      &lt;li&gt;
\[P(B, C|A) = P(B|A) \cdot P(C|A)\]
      &lt;/li&gt;
      &lt;li&gt;
\[P(B|A,C) =P(B|A)\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;probabilities-and-supervised-learning&quot;&gt;Probabilities and Supervised Learning&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Given: Training data consisting of training examples \(data = (x_1, y_1), …, (x_n, y_n)\).&lt;/li&gt;
  &lt;li&gt;Goal: Learn a mapping \(h\) from \(x\) to \(y\).&lt;/li&gt;
  &lt;li&gt;Two approaches:
    &lt;ul&gt;
      &lt;li&gt;Discriminative algorithms learn 
  \(P(y | x)\) 
  directly.&lt;/li&gt;
      &lt;li&gt;Generative algorithms use Bayes rule
  \begin{equation}
  P(y|x) = \frac{P(x|y) \cdot P(y)}{P(x)}
  \end{equation}&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;discriminative-algorithms&quot;&gt;Discriminative Algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Model conditional distribution of the label given the data&lt;/li&gt;
  &lt;li&gt;Learns decision boundaries that separate instances of the different classes.&lt;/li&gt;
  &lt;li&gt;To predict a new example, check on which side of the decision boundary it falls.&lt;/li&gt;
  &lt;li&gt;Examples:
    &lt;ul&gt;
      &lt;li&gt;support vector machine (SVM)&lt;/li&gt;
      &lt;li&gt;decision trees&lt;/li&gt;
      &lt;li&gt;random forests&lt;/li&gt;
      &lt;li&gt;neural networks&lt;/li&gt;
      &lt;li&gt;log-linear models&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;generative-algorithms&quot;&gt;Generative Algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Assume the observed data is being “generated” by a “hidden” class label.&lt;/li&gt;
  &lt;li&gt;Build a different model for each class.&lt;/li&gt;
  &lt;li&gt;To predict a new example, check it under each of the models and see which one matches best.&lt;/li&gt;
  &lt;li&gt;Estimate \(P(x|y)\) and \(P(y)\). Then use bases rule
  \begin{equation}
  P(y|x) = \frac{P(x|y) \cdot P(y)}{P(x)}
  \end{equation}&lt;/li&gt;
  &lt;li&gt;Examples:
    &lt;ul&gt;
      &lt;li&gt;Naive Bayes&lt;/li&gt;
      &lt;li&gt;Hidden Markov Models&lt;/li&gt;
      &lt;li&gt;Gaussian Mixture Models&lt;/li&gt;
      &lt;li&gt;PCFGs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;naive-bayes&quot;&gt;Naive Bayes&lt;/h2&gt;

&lt;h3 id=&quot;rules&quot;&gt;Rules&lt;/h3&gt;
&lt;p&gt;\begin{equation}
P(Label, X_1, …, X_d) = P(Label) \Pi_i P(X_i|Label)
\end{equation}&lt;/p&gt;

&lt;p&gt;\begin{equation}
\begin{split}
    P(Label|X_1, …, X_d) &amp;amp; = \frac{P(Label) \Pi_i P(X_i|Label)}{\Pi_i P(X_i)} &lt;br /&gt;
    &amp;amp; = \alpha [P(Label) \Pi_i P(X_i|Label)]
\end{split}
\end{equation}&lt;/p&gt;

&lt;h3 id=&quot;naive-bayes-classifier&quot;&gt;Naive Bayes Classifier&lt;/h3&gt;
&lt;p&gt;\begin{equation}
y* = \arg \max_y P(y) \Pi_i P(x_i|y)
\end{equation}&lt;/p&gt;

&lt;h3 id=&quot;training-the-naive-bayes-classifier&quot;&gt;Training the Naive Bayes’ Classifier&lt;/h3&gt;
&lt;p&gt;Estimate the prior and posterior probabilities using Maximum Likelihood Estimates (MLE)&lt;/p&gt;

&lt;p&gt;\begin{equation}
P(y) = \frac{Count(y)}{\sum_{y’\in Y}Count(y’)}
\end{equation}&lt;/p&gt;

&lt;p&gt;\begin{equation}
P(x_i|y) = \frac{Count(x_i, y)}{Count(y)}
\end{equation}&lt;/p&gt;

&lt;h3 id=&quot;some-issues-to-consider&quot;&gt;Some Issues to Consider&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;What if there are words that do not appear in the training set? What if it appears only once?&lt;/li&gt;
  &lt;li&gt;What if the plural of a word never appears in the training set?&lt;/li&gt;
  &lt;li&gt;How are extremely common words (e.g., “the”, “a”) handled?&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jiawei Lu</name><email>jl5999@columbia.edu</email></author><category term="studylog" /><category term="nlp" /><summary type="html">Keywords: Language Classification, Probability Review, Machine Learning Background, Naive Bayes’ Classifier.</summary></entry><entry><title type="html">Object Detection for Dummies Part 1: Gradient Vector, HOG, and SS</title><link href="http://localhost:4000/studylog/ODDP1.html" rel="alternate" type="text/html" title="Object Detection for Dummies Part 1: Gradient Vector, HOG, and SS" /><published>2022-02-09T00:00:00-05:00</published><updated>2022-02-09T00:00:00-05:00</updated><id>http://localhost:4000/studylog/ODDP1</id><content type="html" xml:base="http://localhost:4000/studylog/ODDP1.html">&lt;p&gt;Jan 28, 2021.
The raw blog &lt;a href=&quot;https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html&quot;&gt;URL&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;image-gradient-vector&quot;&gt;Image Gradient Vector&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Derivative
    &lt;ul&gt;
      &lt;li&gt;Scalar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Directional Derivative
    &lt;ul&gt;
      &lt;li&gt;Scalar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gradient
    &lt;ul&gt;
      &lt;li&gt;Vector
        &lt;pre&gt;&lt;code class=&quot;language-python=&quot;&gt;import numpy as np
import scipy.signal as sig
data = np.array([[0, 105, 0], [40, 255, 90], [0, 55, 0]])
G_x = sig.convolve2d(data, np.array([[-1, 0, 1]]), mode=&apos;valid&apos;)
G_y = sig.convolve2d(data, np.array([[-1], [0], [1]]), mode=&apos;valid&apos;)
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Common Image Processing Kernels(&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67197912&quot;&gt;Useful URL&lt;/a&gt;)
    &lt;ul&gt;
      &lt;li&gt;Prewitt operator&lt;/li&gt;
      &lt;li&gt;Sobel operator&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;histogram-of-oriented-gradients-hog&quot;&gt;Histogram of Oriented Gradients (HOG)&lt;/h2&gt;
&lt;p&gt;Useful &lt;a href=&quot;https://zhuanlan.zhihu.com/p/85829145&quot;&gt;URL&lt;/a&gt; in zhihu.&lt;/p&gt;

&lt;h3 id=&quot;how-hog-works&quot;&gt;How HOG works&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Preprocess the image, including resizing and color normalization.
    &lt;ul&gt;
      &lt;li&gt;Gamma Correction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;\begin{equation}
f(x) = x^{\gamma}
\end{equation}&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python=&quot;&gt;# Gamma Correction
import cv2
import numpy as np
img = cv2.imread(&apos;gamma.jpg&apos;, 0)
img2 = np.power(img/float(np.max(img)), 1.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the gradient vector of every pixel, as well as its magnitude and direction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;\begin{equation}
g = \sqrt{g_x^2+g_y^2} \ 
\theta = \arctan \frac{g_y}{g_x}
\end{equation}&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python=&quot;&gt;import cv2
import numpy as np

# Read image
img = cv2.imread(&apos;runner.jpg&apos;)
img = np.float32(img) / 255.0  # 归一化

# x,y gradient
gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=1)
gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=1)

# gradient
mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Divide the image into many 8x8 pixel cells. In each cell, the magnitude values of these 64 cells are binned and cumulatively added into 9 buckets of unsigned direction (no sign, so 0-180 degree rather than 0-360 degree; this is a practical choice based on empirical experiments).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Then we slide a 2x2 cells (thus 16x16 pixels) block across the image. In each block region, 4 histograms of 4 cells are concatenated into one-dimensional vector of 36 values and then normalized to have an unit weight. The final HOG feature vector is the concatenation of all the block vectors. It can be fed into a classifier like SVM for learning object recognition tasks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&quot;language-python=&quot;&gt;# HOG
from skimage import feature, exposure
import cv2
image = cv2.imread(&apos;/home/zxd/Pictures/Selection_018.jpg&apos;)
fd, hog_image = feature.hog(image, orientations=9, pixels_per_cell=(16, 16),
                    cells_per_block=(2, 2), visualize=True)

# Rescale histogram for better display
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))

cv2.imshow(&apos;img&apos;, image)
cv2.imshow(&apos;hog&apos;, hog_image_rescaled)
cv2.waitKey(0)==ord(&apos;q&apos;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;image-segmentation-felzenszwalbs-algorithm&quot;&gt;Image Segmentation (Felzenszwalb’s Algorithm)&lt;/h2&gt;

&lt;h3 id=&quot;graph-construction&quot;&gt;Graph Construction&lt;/h3&gt;

&lt;p&gt;There are two approaches to constructing a graph out of an image.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Grid Graph: Each pixel is only connected with surrounding neighbours (8 other cells in total). The edge weight is the absolute difference between the intensity values of the pixels.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nearest Neighbor Graph: Each pixel is a point in the feature space (x, y, r, g, b), in which (x, y) is the pixel location and (r, g, b) is the color values in RGB. The weight is the Euclidean distance between two pixels’ feature vectors.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Jiawei Lu</name><email>jl5999@columbia.edu</email></author><category term="studylog" /><category term="dl" /><summary type="html">Jan 28, 2021. The raw blog URL.</summary></entry><entry><title type="html">Leetcode</title><link href="http://localhost:4000/studylog/leetcode.html" rel="alternate" type="text/html" title="Leetcode" /><published>2022-02-02T00:00:00-05:00</published><updated>2022-02-02T00:00:00-05:00</updated><id>http://localhost:4000/studylog/leetcode</id><content type="html" xml:base="http://localhost:4000/studylog/leetcode.html">&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Two sum&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Hashmap&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add two numbers
    &lt;ul&gt;
      &lt;li&gt;Linked List&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Longest Substring Without Repeating Characters
    &lt;ul&gt;
      &lt;li&gt;Two pointers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Median of Two Sorted Arrays
    &lt;ul&gt;
      &lt;li&gt;Median&lt;/li&gt;
      &lt;li&gt;Binary Search&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Longest Palindromic Substring
    &lt;ul&gt;
      &lt;li&gt;DP&lt;/li&gt;
      &lt;li&gt;Java vs Python&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Regular Expression Matching
    &lt;ul&gt;
      &lt;li&gt;Recursion&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Container With Most Water
    &lt;ul&gt;
      &lt;li&gt;Two pointers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;3 Sum
    &lt;ul&gt;
      &lt;li&gt;2 sum&lt;/li&gt;
      &lt;li&gt;Hashmap&lt;/li&gt;
      &lt;li&gt;sort&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Letter Combinations of a Phone Number
    &lt;ul&gt;
      &lt;li&gt;Hashmap&lt;/li&gt;
      &lt;li&gt;Recursion&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Remove Nth Node From End of List
    &lt;ul&gt;
      &lt;li&gt;Symmetric&lt;/li&gt;
      &lt;li&gt;Two pointers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Valid Parentheses
    &lt;ul&gt;
      &lt;li&gt;Stack&lt;/li&gt;
      &lt;li&gt;Hashmap for pair&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Generate Parentheses
    &lt;ul&gt;
      &lt;li&gt;DFS&lt;/li&gt;
      &lt;li&gt;Stack&lt;/li&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Merge k Sorted Lists
    &lt;ul&gt;
      &lt;li&gt;Priority Queue
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Queue&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PriorityQueue&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;Python &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sorted(list)&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reverse Nodes in k-Group
    &lt;ul&gt;
      &lt;li&gt;Reverse list&lt;/li&gt;
      &lt;li&gt;6 pointers: dummy, jump, l, r, prev, cur&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Next Permutation
    &lt;ul&gt;
      &lt;li&gt;Find Pattern: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nums[i-1] &amp;lt; nums[i]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Decreasing List&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Longest Valid Parentheses
    &lt;ul&gt;
      &lt;li&gt;Find Pattern: If ‘)’ more than ‘(‘, reset&lt;/li&gt;
      &lt;li&gt;Stack&lt;/li&gt;
      &lt;li&gt;Two traverse&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Search in Rotated Sorted Array
    &lt;ul&gt;
      &lt;li&gt;Binary Search&lt;/li&gt;
      &lt;li&gt;Mind &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left &amp;lt;= mid&lt;/code&gt; since &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mid = (left + right)//2&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Find First and Last Position of Element in Sorted Array
    &lt;ul&gt;
      &lt;li&gt;Binary Search&lt;/li&gt;
      &lt;li&gt;Find left most: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left = mid + 1, right = mid&lt;/code&gt;
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python = 
  while left &amp;lt; right:
      mid = (left + right) // 2
      if nums[mid] &amp;lt; target:
          left = mid + 1
      else:
          right = mid
 &lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Find right most: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left = mid, right = mid - 1&lt;/code&gt;
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python = 
  while left &amp;lt; right:
      mid = (left + right + 1) // 2
      if nums[mid] &amp;gt; target:
          right = mid - 1
      else:
          left = mid
 &lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Search Insert Position
    &lt;ul&gt;
      &lt;li&gt;Binary Search&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Combination Sum
    &lt;ul&gt;
      &lt;li&gt;Backtracking/DFS
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;First Missing Positive
    &lt;ul&gt;
      &lt;li&gt;Find Pattern: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[1,2,...,n+1]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Hash &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nums[nums[i]%n] += n&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Trapping Rain Water
    &lt;ul&gt;
      &lt;li&gt;DP: store leftMax and rightMax&lt;/li&gt;
      &lt;li&gt;Two pointers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Jump Game II
    &lt;ul&gt;
      &lt;li&gt;Two pointers: left for n steps, right for n+1 steps&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Permutations
    &lt;ul&gt;
      &lt;li&gt;DFS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rotate Image
    &lt;ul&gt;
      &lt;li&gt;List transportation with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zip()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rotate = flip + trans&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Group Anagrams
    &lt;ul&gt;
      &lt;li&gt;permutations have the same characters: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sorted()&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dict&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Maximum Subarray
    &lt;ul&gt;
      &lt;li&gt;Divide and Conquer&lt;/li&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Jump Game
    &lt;ul&gt;
      &lt;li&gt;two pointers&lt;/li&gt;
      &lt;li&gt;from end to start: where is the last reachable point&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Merge Intervals
    &lt;ul&gt;
      &lt;li&gt;Graph&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort()&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Unique Paths
    &lt;ul&gt;
      &lt;li&gt;DP&lt;/li&gt;
      &lt;li&gt;Math $C_m^n$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Minimum Path Sum
    &lt;ul&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Climbing Stairs
    &lt;ul&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Edit Distance
    &lt;ul&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Search a 2D Matrix
    &lt;ul&gt;
      &lt;li&gt;Binary Search: $m \times n$ sorted array&lt;/li&gt;
      &lt;li&gt;if element not in list, find the left boundary: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mid = (left + right)//2&lt;/code&gt;,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right -= 1&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sort Colors
    &lt;ul&gt;
      &lt;li&gt;count sort&lt;/li&gt;
      &lt;li&gt;*Dutch National Flag Problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Minimum Window Substring
    &lt;ul&gt;
      &lt;li&gt;Sliding window, two pointers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Subsets
    &lt;ul&gt;
      &lt;li&gt;Backtracking&lt;/li&gt;
      &lt;li&gt;Bitmask&lt;/li&gt;
      &lt;li&gt;DP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Word Search
    &lt;ul&gt;
      &lt;li&gt;Backtracking / DFS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;oa&quot;&gt;OA&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Merge Sort: Counting Inversions&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&quot;language-python=&quot;&gt;#!/bin/python3

import math
import os
import random
import re
import sys

#
# Complete the &apos;countInversions&apos; function below.
#
# The function is expected to return a LONG_INTEGER.
# The function accepts INTEGER_ARRAY arr as parameter.
#

def countInversions(arr):
    # Write your code here
    temp_arr = [0]*len(arr)
    return mergeSort(arr, temp_arr, 0, len(arr) - 1)

def mergeSort(arr, temp_arr, left, right):
    inv_cnt = 0
    if left &amp;lt; right:
        mid = (left + right) // 2
        inv_cnt += mergeSort(arr, temp_arr, left, mid)
        inv_cnt += mergeSort(arr, temp_arr, mid + 1, right)
        inv_cnt += merge(arr, temp_arr, left, mid, right)
    return inv_cnt

def merge(arr, temp_arr, left, mid, right):
    i, j, k = left, mid+1, left
    inv_cnt = 0
    while i &amp;lt;= mid and j &amp;lt;= right:
        if arr[i] &amp;gt; arr[j]:
            inv_cnt += mid - i + 1
            temp_arr[k] = arr[j]
            j += 1

        else:
            temp_arr[k] = arr[i]
            i += 1
        k += 1
    
    while i &amp;lt;= mid:
        temp_arr[k] = arr[i]
        i += 1
        k += 1
    while j &amp;lt;= right:
        temp_arr[k] = arr[j]
        j += 1
        k += 1
    
    for x in range(left, right + 1):
        arr[x] = temp_arr[x]
    
    return inv_cnt
    

if __name__ == &apos;__main__&apos;:
    fptr = open(os.environ[&apos;OUTPUT_PATH&apos;], &apos;w&apos;)

    t = int(input().strip())

    for t_itr in range(t):
        n = int(input().strip())

        arr = list(map(int, input().rstrip().split()))

        result = countInversions(arr)

        fptr.write(str(result) + &apos;\n&apos;)

    fptr.close()

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Stars and Bars:
```python=
def stars_and_bars(s, startIndex, endIndex):
 bars = {}&lt;/p&gt;

    &lt;p&gt;cnt = 0
 for i in range(len(s)):
     if s[i] == “|”:
         bars[i] = cnt
         cnt += 1
 lst = list(bars)
 startIndex, endIndex = [x-1 for x in startIndex], &lt;br /&gt;
                        [x-1 for x in endIndex]
 start_bar, end_bar = [], []&lt;/p&gt;

    &lt;p&gt;for i in range(len(startIndex)):
     start_bar.append(binary_start(lst, startIndex[i]))
 for i in range(len(endIndex)):
     end_bar.append(binary_end(lst, endIndex[i]))&lt;/p&gt;

    &lt;p&gt;print(bars)
 print(start_bar, end_bar)&lt;/p&gt;

    &lt;p&gt;res = 0
 for i in range(len(start_bar)):&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; res += max(0, (end_bar[i] - start_bar[i] - 1) - \
            (bars[end_bar[i]] - bars[start_bar[i]] - 1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;return res&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;def binary_start(nums, target):
    left, right = 0, len(nums) -1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while left &amp;lt; right:
    mid = (left+right)//2
    if nums[mid] == target:
        return nums[mid]
    elif nums[mid] &amp;gt; target:
        right = mid
    else:
        left = mid + 1
return nums[right]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;def binary_end(nums, target):
    left, right = 0, len(nums) -1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while left &amp;lt; right:
    mid = (left+right+1)//2
    if nums[mid] == target:
        return nums[mid]
    elif nums[mid] &amp;gt; target:
        right = mid - 1
    else:
        left = mid  
return nums[left]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;```&lt;/p&gt;</content><author><name>Jiawei Lu</name><email>jl5999@columbia.edu</email></author><category term="studylog" /><category term="coding-interview" /><summary type="html">Two sum</summary></entry></feed>