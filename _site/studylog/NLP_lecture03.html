<!DOCTYPE html>
<html lang="zh, en">







<head>
  






  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NLP Lecture 03: n-gram language models | Jiawei Lu</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="NLP Lecture 03: n-gram language models" />
<meta name="author" content="Jiawei Lu" />
<meta property="og:locale" content="zh, en" />
<meta name="description" content="Keywords: n-gram language models" />
<meta property="og:description" content="Keywords: n-gram language models" />
<link rel="canonical" href="http://localhost:4000/studylog/NLP_lecture03.html" />
<meta property="og:url" content="http://localhost:4000/studylog/NLP_lecture03.html" />
<meta property="og:site_name" content="Jiawei Lu" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-26T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="NLP Lecture 03: n-gram language models" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jiawei Lu"},"dateModified":"2022-01-26T00:00:00-08:00","datePublished":"2022-01-26T00:00:00-08:00","description":"Keywords: n-gram language models","headline":"NLP Lecture 03: n-gram language models","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/studylog/NLP_lecture03.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/jiawei.jpg"},"name":"Jiawei Lu"},"url":"http://localhost:4000/studylog/NLP_lecture03.html"}</script>
<!-- End Jekyll SEO tag -->


  

  
    <meta name="keywords" content="Jiawei Lu,jiawei lu,columbia,Deep Learning,Reinforcement Learning">
  



  <meta name="theme-color" content="rgb(25,55,71)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Jiawei Lu">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="Jiawei Lu">

<meta name="generator" content="Hydejack v9.1.5" />



<link rel="alternate" href="http://localhost:4000/studylog/NLP_lecture03.html" hreflang="zh, en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Jiawei Lu" />


<link rel="shortcut icon"    href="/assets/icons/favicon.png">
<link rel="apple-touch-icon" href="/assets/img/favicon.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">

  <link rel="dns-prefetch" href="/assets/js/search-worker-9.1.5.js" as="worker" id="_hrefSearch">





  <link rel="stylesheet" href="https://unpkg.com/applause-button/dist/applause-button.css">
  <script src="https://unpkg.com/applause-button/dist/applause-button.js"></script>


<!-- For sidebar folder -->
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
<script src="/assets/js/sidebar-folder.js"></script>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-68290006-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-68290006-3');
</script>

<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script");n.src=e,t&&a(n,"load",t,{once:!0});t=c.scripts[0];return t.parentNode.insertBefore(n,t),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._advertise = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2023-12-16T23:19:14-08:00',
  };
  w._clapButton = false;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>



<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.5.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+KR%7CJetBrains+Mono%7CNanum+Gothic+Coding&display=swap" id="_fontsPreload">




<!--<![endif]-->





</head>

<body class="dark-mode no-break-layout no-large-headings">
  
<script>
  window._sunrise = 6;
  window._sunset =  18;
  !function(e,s){var d="light-mode",o="dark-mode",a=(new Date).getHours();"matchMedia"in e&&e.matchMedia("(prefers-color-scheme)")||(o=(e=a<=e._sunrise||a>=e._sunset?o:d)==o?d:o,s.body.classList.add(e),s.body.classList.remove(o))}(window,document);

</script>



<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/studylog/">studylog</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>NLP_lecture03.html</span>
        
      </li>
    
  
</ul></nav>

  










<article id="post-studylog-NLP_lecture03" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        NLP Lecture 03: n-gram language models
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2022-01-26T00:00:00-08:00">26 Jan 2022</time> in <a href="/studylog/" class="flip-title">Study Blog</a> on <a href="/tag-nlp/" class="flip-title">Natrual Laguage Processing</a>
      </span>
      
        
      
    </div>

    
    

    



  <div class="hr pb0"></div>


  </header>

  
    <p>Keywords: n-gram language models</p>

<h2 id="language-modeling">Language Modeling</h2>

<ul>
  <li>Task: predict the next word given the context.</li>
  <li>Used in speech recognition, handwritten character recognition, spelling correction, text entry UI, machine translation,…</li>
</ul>

<h2 id="probability-of-the-next-word">Probability of the Next Word</h2>
<ul>
  <li>Idea: We do not need to model domain, syntactic, and lexical knowledge perfectly.</li>
  <li>Instead, we can rely on the notion of probability of a sequence (letters, words…).</li>
</ul>

<h2 id="markov-assumption">Markov Assumption</h2>
<ul>
  <li>\(P(w_n|w_1, w_2, ..., w_{n-1})\)
  is difficult to estimate.</li>
  <li>The longer the sequence becomes, the less likely \(w_1 w_2 w_3 ... w_{n-1}\) will appear in training data.</li>
  <li>Instead, we make the following simple independence assumption (Markov assumption): The probability to see wn depends only on the previous \(k-1\) words.
  \begin{equation}
  P(w_n|w_1, w_2, w_3, …, w_{n-1}) \approx P(w_n|w_{n-k+1}, …, w_{n-1})
  \end{equation}</li>
</ul>

<h2 id="n-grams">n-grams</h2>
<ul>
  <li>The sequence \(w_n\) is a unigram.</li>
  <li>The sequence \(w_{n-1}, w_n\) is a bigram.</li>
  <li>The sequence \(w_{n-2}, w_{n-1}, w_n\) is a trigram.</li>
  <li>The sequence \(w_{n-3}, w_{n-2}, w_{n-1}, w_n\) is a quadrigram…</li>
</ul>

<h2 id="bi-gram-language-model">Bi-gram Language Model</h2>

<ul>
  <li>
    <p>Using the Markov assumption and the chain rule:
  \begin{equation}
  P(w_1, w_2, w_3, …, w_n) \approx P(w_1) \cdot P(w_2|w_1) \cdot P(w_3|w_2) \cdots P(w_n|w_{n-1})
  \end{equation}</p>
  </li>
  <li>
    <p>More consistent to use only bigrams:
  \begin{equation}
  P(w_1|start) \cdot P(w_2|w_1) \cdot P(w_3|w_2) \cdots P(w_n|w_{n-1}) \cdot P(end|w_n)
  \end{equation}</p>
  </li>
</ul>

<h2 id="variable-length-language-models">Variable-Length Language Models</h2>

<ul>
  <li>We typically don’t know what the length of the sentence is.</li>
  <li>Instead, we use a special marker END/STOP that indicates the end of a sentence.</li>
  <li>We typically just augment the sentence with START and END/STOP markers to provide the appropriate context. 
(START i want to eat Chinese food END)</li>
</ul>

<h2 id="log-probabilities">Log Probabilities</h2>
<ul>
  <li>Probabilities can become very small (a few orders of magnitude per token).</li>
  <li>
    <p>We often work with log probabilities in practice.
  \begin{equation}
  p(w_1…w_n) = \Pi_{i=1}^np(w_i|w_{i-1})
  \end{equation}</p>

    <p>\begin{equation}
  \log p(w_1…w_n) = \sum_{i=1}^n \log p(w_i|w_{i-1})
  \end{equation}</p>
  </li>
</ul>

<h2 id="estimating-n-gram-probabilities">Estimating n-gram Probabilities</h2>

<ul>
  <li>
    <p>We can estimate n-gram probabilities using maximum likelihood estimates.
  \begin{equation}
  p(w|u) = \frac{count(u,w)}{count(u)}
  \end{equation}</p>
  </li>
  <li>
    <p>Or for trigrams:
  \begin{equation}
  p(w|u, v) = \frac{count(w,u,w)}{count(u, v)}
  \end{equation}</p>
  </li>
</ul>

<h2 id="unseen-tokens">Unseen Tokens</h2>

<ul>
  <li>Typical approach to unseen tokens:
    <ul>
      <li>Start with a specific lexicon of known tokens.</li>
      <li>Replace all tokens in the training and testing corpus that are not in the lexicon with an <code class="language-plaintext highlighter-rouge">UNK</code> token.</li>
    </ul>
  </li>
  <li>Practical approach:
    <ul>
      <li>Lexicon contains all words that appear more than <code class="language-plaintext highlighter-rouge">k</code> times in the training corpus.</li>
      <li>Replace all other tokens with UNK.</li>
    </ul>
  </li>
</ul>

<h2 id="unseen-contexts">Unseen Contexts</h2>
<ul>
  <li>Two basic approaches:
    <ul>
      <li>Smoothing / Discounting: Move some probability mass from seen trigrams to unseen trigrams.</li>
      <li>Back-off: Use n-1-…, n-2-… grams to compute n-gram probability.</li>
    </ul>
  </li>
  <li>Other techniques:
    <ul>
      <li>Class-based backoff, use back-off probability for a specific word class / part-of-speech.</li>
    </ul>
  </li>
</ul>

<h2 id="zipfs-law">Zipf’s Law</h2>
<ul>
  <li>Problem: n-grams (and most other linguistic phenomena) follow a Zipfian distribution.</li>
  <li>A few words occur very frequently.</li>
  <li>
    <p>Most words occur very rarely. Many are seen only once.</p>
  </li>
  <li>Zipf’s law: a word’s frequency is approximately inversely proportional to its rank in the word distribution list.</li>
</ul>

<h2 id="smoothing">Smoothing</h2>
<p>Smoothing flattens spiky distributions.</p>

<h3 id="additive-smoothing">Additive Smoothing</h3>
<ul>
  <li>
    <p>Classic approach: Laplacian, a.k.a. additive smoothing.</p>

    <p>\begin{equation}
  P(w_i) = \frac{count(w_i) + 1}{N+V}
  \end{equation}</p>

    <ul>
      <li>N is the number of tokens</li>
      <li>V is the number of types (i.e. size of the vocabulary)</li>
    </ul>
  </li>
  <li>
    <p>\begin{equation}
  P(w|u) = \frac{count(u, w) + 1}{count(u) + V}
  \end{equation}</p>
  </li>
  <li>
    <p>Inaccurate in practice.</p>
  </li>
</ul>

<h2 id="linear-interpolation">Linear Interpolation</h2>
<ul>
  <li>
    <p>Use denser distributions of shorter ngrams to “fill in” sparse ngram distributions.</p>

    <p>\begin{equation}
  P(w|u, v) = \lambda_1 \cdot p_{mle}(w|u,v) + \lambda_2 \cdot p_{mle}(w|v) + \lambda_3 \cdot p_{mle}(w)
  \end{equation}</p>
  </li>
  <li>Where, \(\lambda_1, \lambda_2, \lambda_3 &gt; 0\) and \(\lambda_1 + \lambda_2 + \lambda_3 = 1\).</li>
  <li>Works well in practice (but not a lot of theoretical justification why).</li>
  <li>Parameters can be estimated on development data (for example, using Expectation Maximization).</li>
</ul>

<h2 id="discounting">Discounting</h2>
<ul>
  <li>Idea: set aside some probability mass, then fill in the missing mass using back-off.</li>
  <li>\(count^*(v, w) = count(v, w) - \beta\) where \(0&lt;\beta&lt;1\).</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Then for all seen bigrams: $$ p(w</td>
          <td>v) = \frac{count^*(v, w)}{count(v)}.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>For each context v the missing probability mass is
  \begin{equation}
  \alpha(v) = 1 - \sum_{w:c(v,w)&gt;0} \frac{count^*(v, w)}{count(v)}
  \end{equation}</li>
  <li>We can now divide this held-out mass between the unseen words (evenly or using back-off).</li>
</ul>

<h3 id="katz-backoff">Katz’ Backoff</h3>
<ul>
  <li>
    <p>Divide the held-out probability mass proportionally to the unigram probability of the unseen words in context v.</p>

    <p>\begin{equation}
  p(w|v) = 
  \begin{cases}
  &amp; \frac{count^*(v, w)}{count(v)} &amp; if count(v,w) &gt; 0, <br />
  &amp; \alpha(v) \times \frac{p_{mle}(w)}{\sum_{u:count(v,u) = 0}p_{mle(u)}} &amp; otherwise.
  \end{cases}
  \end{equation}</p>
  </li>
</ul>

<h2 id="evaluating-n-gram-models">Evaluating n-gram models</h2>
<ul>
  <li>Extrinsic evaluation: Apply the model in an application (for example language classification). Evaluate the application.</li>
  <li>Intrinsic evaluation: measure how well the model approximates unseen language data.
    <ul>
      <li>Can compute the probability of each sentence according to the model. Higher probability -&gt; better model.</li>
      <li>Typically we compute Perplexity instead.</li>
    </ul>
  </li>
</ul>

<h3 id="perplexity">Perplexity</h3>
<ul>
  <li>Perplexity (per word) measures how well the ngram model predicts the sample.</li>
  <li>Given a corpus of ‘m’ sentences ‘\(s_i\)’, where ‘M’ is total number of tokens in the corpus</li>
  <li>Perplexity is defined as \(2^{-l}\), where \(l = \frac{1}{M} \sum_{i=1}^m \log_2 p(s_i)\).</li>
  <li>Lower perplexity = better model. Intuition:
    <ul>
      <li>Assume we are predicting one word at a time.</li>
      <li>With uniform distribution, all successor words are equally likely. Perplexity is equal to vocabulary size.
• Perplexity can be thought of as “effective vocabulary size”.</li>
    </ul>
  </li>
</ul>

  
</article>



<applause-button class="mb6"
    color=rgb(79,177,186)
    url=http://localhost:4000/studylog/NLP_lecture03.html >
  </applause-button>






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>MSEE student at <a href="https://www.ee.columbia.edu/">Columbia Univeristy</a>.<br />
Please check my <a href="/resume/">Resume</a> to find out more about me!<br /></p>



  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/jiaweilucolumbia" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/JiaweiLu1999" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://instagram.com/javeylew" title="Instagram" class="no-mark-external">
      <span class="icon-instagram"></span>
      <span class="sr-only">Instagram</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:jl5999@columbia.edu" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
    
<aside class="comments related" role="complementary">
  <h2 class="hr-bottom">Comments</h2>
  

  
  
    <script src="https://giscus.app/client.js"
            data-repo=JiaweiLu1999/JiaweiLu1999.github.io
            data-repo-id=R_kgDOGt0vAg
            data-category=Comments
            data-category-id=DIC_kwDOGt0vAs4CA218
            data-mapping=pathname
            data-reactions-enabled=1
            data-emit-metadata=0
            data-theme=dark_dimmed
            data-lang=en
            crossorigin=anonymous
            async>
    </script>
  


</aside>


  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© 2022 Jiawei Lu. All rights reserved.
</small></p>
  
  
  
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(25,55,71);background-image:url(/assets/img/sidebar-bg.jpg)"></div>

    <div class="sidebar-sticky no-fouc">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/jiawei.jpg" class="avatar" alt="Jiawei Lu" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">Jiawei Lu</h2></a>
    
    
      <p class="">
        MSEE @ Columbia

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
  
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
        
        
        <li>
          
          <div class="list-wrapper">
            <a  href="/about/" class="sidebar-nav-item"  >About Me</a>
            
          </div>
          
        </li>
      
    
  
    
      
        
        
        <li>
          
          <div class="list-wrapper">
            <a  href="/resume/" class="sidebar-nav-item"  >Resume</a>
            
          </div>
          
        </li>
      
    
  
    
      
        
        
        <li>
          
          <div class="list-wrapper">
            <a  href="/projects.html" class="sidebar-nav-item"  >Projects</a>
            
          </div>
          
        </li>
      
    
  
    
      
        
        
        <li>
          
            <input type="checkbox" id="folder-checkbox-12" />
          
          <div class="list-wrapper">
            <a  href="/studylog/" class="sidebar-nav-item"  >Study Blog</a>
            
              <button class="spread-btn" onclick="javascript:spread(12)">
                <label id="spread-icon-12" class="material-icons">arrow_right</label>
              </button>
            
          </div>
          
            <ul class="list-body">
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-zklab/">Zoran Kostic Lab</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-cv/">Computer Vision</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-diary/">Diary</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-dl/">Deep Learning</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-ml/">Machine Learning</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-nlp/">Natrual Laguage Processing</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-cn/">Computer Networking</a>
                </li>
            
          
            
                <li>
                  <a class="sidebar-nav-subitem" href="/tag-coding-interview/">Coding Interview</a>
                </li>
            </ul>
          
        </li>
      
    
  
    
      
        
        
        <li>
          
          <div class="list-wrapper">
            <a  href="/tags/" class="sidebar-nav-item"  >Tags</a>
            
          </div>
          
        </li>
      
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/jiaweilucolumbia" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/JiaweiLu1999" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://instagram.com/javeylew" title="Instagram" class="no-mark-external">
      <span class="icon-instagram"></span>
      <span class="sr-only">Instagram</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:jl5999@columbia.edu" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
<script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
<script src="/assets/js/hydejack-9.1.5.js" type="module"></script>
<script src="/assets/js/LEGACY-hydejack-9.1.5.js" nomodule defer></script>




<script type="module">
  if ('serviceWorker' in navigator) {
    /**/
    navigator.serviceWorker.getRegistration()
      .then(r => r.unregister())
      .catch(() => {});
    /**/
  }
</script>
<!--<![endif]-->

  


<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <clap-config>
    <clap-text at="1">Keep going!</clap-text>
    <clap-text at="2">Keep going ×2!</clap-text>
    <clap-text at="3">Give me more!</clap-text>
    <clap-text at="5">Thank you, thank you</clap-text>
    <clap-text at="7">Far too kind!</clap-text>
    <clap-text at="10">Never gonna give me up?</clap-text>
    <clap-text at="14">Never gonna let me down?</clap-text>
    <clap-text at="20">Turn around and desert me!</clap-text>
    <clap-text at="30">You're an addict!</clap-text>
    <clap-text at="40">Son of a clapper!</clap-text>
    <clap-text at="50">No way</clap-text>
    <clap-text at="60">Go back to work!</clap-text>
    <clap-text at="70">This is getting out of <em>hand</em></clap-text>
    <clap-text at="80">Unbelievable</clap-text>
    <clap-text at="90">PREPOSTEROUS</clap-text>
    <clap-text at="100">I N S A N I T Y</clap-text>
    <clap-text at="185"><span style="font-family:monospace">FEED ME A STRAY CAT</span></clap-text>
  </clap-config>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>

    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

  
    <template id="_cookies-banner-template">
  <div id="_cookies-banner" class="navbar fixed-bottom CookiesOK">
    <div class="content">
      <div class="nav-btn-bar">
        <small class="faded">
          <span>This site uses cookies. <a href="/cookies-policy/">Cookies Policy</a>.
</span>
          <button id="_cookies-ok" class="btn btn-primary btn-sm">Okay</button>
        </small>
      </div>
    </div>
  </div>
</template>

  
  
    <template id="_dark-mode-template">
  <button id="_dark-mode" class="nav-btn no-hover" >
    <span class="sr-only">Dark Mode</span>
    <span class="icon-brightness-contrast"></span>
  </button>
</template>

  
  
    <template id="_search-template">
  <button id="_search" class="nav-btn no-hover">
    <label class="sr-only" for="_search-input">Search</label>
    <span class="icon-search"></span>
  </button>
  <div id="_search-box">
    <div class="nav-btn">
      <span class="icon-search"></span>
    </div>
    <input
      id="_search-input"
      type="search"
      class="form-control form-control-lg nav-btn"
      placeholder="Build with JEKYLL_ENV=production to enable search."
    />
    <button type="reset" class="nav-btn no-hover">
      <span class="sr-only">Close</span>
      <span class="icon-cross"></span>
    </button>
  </div>
  <div id="_hits"></div>
</template>

  
</div>


</body>
</html>
